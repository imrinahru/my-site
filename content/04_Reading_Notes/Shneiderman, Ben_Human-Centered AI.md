---
title: Ben Shneiderman (2022) — Human-Centered AI
date: 2025-07-15
tags:
  - reading
  - HCD
  - AI
  - ux-design
draft: false
summary: Applying human-centered design principles to AI.
link:
---
## Background and Premise

Shneiderman challenges the common assumption that technology’s purpose is to mimic or replace humans. Instead, he argues that technology should **serve human needs**, emphasizing design principles that **amplify, augment, empower, and enhance human performance**.

> “Design the system to make users the initiators of actions rather than the responders.”  
> — _Eight Golden Rules of Interface Design_, No.7

His work advocates for **Human–Computer Interaction (HCI)**, **information visualization**, and **design thinking**, consistently framing technology as a tool that extends human agency rather than substitutes it.

---

## Core Concepts of Human-Centered AI (HCAI)

- **Goal:** Create AI systems that _empower_ rather than _replace_ people.
    
- **Approach:** Combine **AI-based intelligent algorithms** with **human-centered design thinking** to form a new synthesis — _Human-Centered AI_.
    
- **Outcome:** Increase human control, creativity, and responsibility within highly automated systems.
    

HCAI systems aim to:

- Amplify and enhance human performance through automation.
    
- Serve **human values** such as rights, justice, and dignity.
    
- Support **human goals** like self-efficacy, creativity, and social connection.
    
- Balance **high human control** with **high automation** — these are not opposing but _complementary_ aims.
    

---

## Design Frameworks and Metaphors

Shneiderman introduces **four metaphors** to combine AI research goals with human-centered design:

1. **Intelligent Agents and Supertools** – AI as powerful extensions of human capacity.
    
2. **Teammates and Tele-bots** – AI as collaborators or assistants.
    
3. **Assured Autonomy and Control Centers** – ensuring safety and oversight.
    
4. **Social Robots and Active Appliances** – AI embedded in everyday life.
    

The **HCAI framework** guides creative designers to imagine highly automated systems that _preserve human control_ while embedding advanced automation and machine learning.

---

## Examples of HCAI Systems

- **Navigation apps:** Offer alternative routes and estimated times, keeping drivers in control.
    
- **E-commerce:** Empower users through transparent information (pricing, reviews, options).
    
- **Everyday devices:** Elevators, washing machines, and check-in kiosks offer meaningful controls for reliable, quick use.
    

More complex examples of **supertools** include:

- Tools for architects designing energy-efficient buildings.
    
- Data analysis systems that help journalists uncover corruption.
    
- Clinical systems for early detection of medical conditions.
    
- AI systems for auditors or watchdogs to identify bias in hiring or lending decisions.

> _Comment:_ These examples are true but reflect only a limited level of human freedom, as control is often pre-structured. Social and economic structure is excluded from the analysis.


---

## Broader Implications and Challenges

The central challenge is to **chart a path** between:

- **Utopian visions:** happy users, thriving businesses, smart cities.
    
- **Dystopian outcomes:** surveillance capitalism, frustrated users, political manipulation.
    

To succeed, the **HCAI community must reframe its language and imagery**, away from anthropomorphic depictions (e.g., robot hands touching human hands) toward collaboration-centered metaphors that highlight _human agency through computational tools_.

---

## Human Control and Trust

Trust and safety are central to the HCAI vision. For example:

> A car that blocks a driver with high blood alcohol levels improves public safety, but if it malfunctions during an emergency (e.g., rushing to a hospital), it undermines trust.

Thus, the goal is not merely _control_, but **trustworthy systems** that serve _human intentions and contexts_ reliably.

---

## Reflection

- Shneiderman argues for _more human control and more machine automation_ — a **non-zero-sum** relationship.
    
- However, _human control_ may not always be the key indicator of good design.
    
    - What matters more is **human experience**: Does automation reduce or enrich it?
        
    - **Repetition**, for instance, can be a meaningful experience rather than inefficiency.
        
    - Here, **feminist theory** becomes relevant for rethinking care, relationality, and embodied experience in human–machine interactions.

The Human-Centered AI framework is persuasive in emphasizing human empowerment and ethical responsibility. Yet, it risks overvaluing _control_ while underexamining _experience_ — the qualitative aspects of human–technology relations.  
A more critical perspective, perhaps informed by feminist or phenomenological thought, could ask not only _who controls_, but _what kinds of experience, care, and creativity_ automation enables or forecloses.

---

## Additional Links/Books

- **AI for Good** — [https://ai4good.org/](https://ai4good.org/)
- **DataKind** — [https://www.datakind.org/](https://www.datakind.org/)
- **IBM Watson AI XPRIZE** — [https://www.xprize.org/prizes/artificial-intelligence](https://www.xprize.org/prizes/artificial-intelligence)
- **United Nations AI for Good Global Summit** — [https://aiforgood.itu.int/about-us/](https://aiforgood.itu.int/about-us/)
- Dubber,M.D.,Pasquale, F. andDas,S., eds. (2020). The Oxford Handbookof Ethics of AI. New York: Oxford University Press.
- Braunschweig, B. and Ghallab, M., eds. (2021). Reflections on Artificial Intelligence for Humanity. New York: Springer.


